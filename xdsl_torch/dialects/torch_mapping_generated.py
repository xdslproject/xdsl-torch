###
# This dialect is automatically generated by tools/gen_torch_dialect.py
# Please don't edit it manually!
###


from typing import Any

import torch

from xdsl_torch.dialects.torch_generated import *

XDSL_TORCH_OPS: dict[Any, type] = {
    torch.ops.aten._assert_async.default: Torch_Aten_AssertAsyncOp,  # type: ignore
    torch.ops.aten.detach.default: Torch_AtenDetachOp,  # type: ignore
    torch.ops.aten.view_as_real.default: Torch_AtenViewAsRealOp,  # type: ignore
    torch.ops.aten.view_as_complex.default: Torch_AtenViewAsComplexOp,  # type: ignore
    torch.ops.aten.set_.source_Tensor: Torch_AtenSet_SourceTensorOp,  # type: ignore
    torch.ops.aten.set_.default: Torch_AtenSet_Op,  # type: ignore
    torch.ops.aten.lift_fresh.default: Torch_AtenLiftFreshOp,  # type: ignore
    torch.ops.aten.lift_fresh_copy.default: Torch_AtenLiftFreshCopyOp,  # type: ignore
    torch.ops.aten.nonzero.default: Torch_AtenNonzeroOp,  # type: ignore
    torch.ops.aten.masked_select.default: Torch_AtenMaskedSelectOp,  # type: ignore
    torch.ops.aten.copy_.Tensor: Torch_AtenCopy_TensorOp,  # type: ignore
    torch.ops.aten._nested_view_from_buffer.default: Torch_Aten_NestedViewFromBufferOp,  # type: ignore
    torch.ops.aten._nested_view_from_buffer_copy.default: Torch_Aten_NestedViewFromBufferCopyOp,  # type: ignore
    torch.ops.aten.atan2.default: Torch_AtenAtan2Op,  # type: ignore
    torch.ops.aten.arctan2.default: Torch_AtenArctan2Op,  # type: ignore
    torch.ops.aten.bitwise_and.Tensor: Torch_AtenBitwiseAndTensorOp,  # type: ignore
    torch.ops.aten.bitwise_or.Tensor: Torch_AtenBitwiseOrTensorOp,  # type: ignore
    torch.ops.aten.bitwise_xor.Tensor: Torch_AtenBitwiseXorTensorOp,  # type: ignore
    torch.ops.aten.bitwise_left_shift.Tensor: Torch_AtenBitwiseLeftShiftTensorOp,  # type: ignore
    torch.ops.aten.bitwise_right_shift.Tensor: Torch_AtenBitwiseRightShiftTensorOp,  # type: ignore
    torch.ops.aten.div.Tensor: Torch_AtenDivTensorOp,  # type: ignore
    torch.ops.aten.divide.Tensor: Torch_AtenDivideTensorOp,  # type: ignore
    torch.ops.aten.floor_divide.default: Torch_AtenFloorDivideOp,  # type: ignore
    torch.ops.aten.fmod.Tensor: Torch_AtenFmodTensorOp,  # type: ignore
    torch.ops.aten.logaddexp.default: Torch_AtenLogaddexpOp,  # type: ignore
    torch.ops.aten.logaddexp2.default: Torch_AtenLogaddexp2Op,  # type: ignore
    torch.ops.aten.mul.Tensor: Torch_AtenMulTensorOp,  # type: ignore
    torch.ops.aten.multiply.Tensor: Torch_AtenMultiplyTensorOp,  # type: ignore
    torch.ops.aten.nextafter.default: Torch_AtenNextafterOp,  # type: ignore
    torch.ops.aten.remainder.Tensor: Torch_AtenRemainderTensorOp,  # type: ignore
    torch.ops.aten.true_divide.Tensor: Torch_AtenTrueDivideTensorOp,  # type: ignore
    torch.ops.aten.eq.Tensor: Torch_AtenEqTensorOp,  # type: ignore
    torch.ops.aten.ne.Tensor: Torch_AtenNeTensorOp,  # type: ignore
    torch.ops.aten.le.Tensor: Torch_AtenLeTensorOp,  # type: ignore
    torch.ops.aten.ge.Tensor: Torch_AtenGeTensorOp,  # type: ignore
    torch.ops.aten.greater.Tensor: Torch_AtenGreaterTensorOp,  # type: ignore
    torch.ops.aten.greater_equal.Tensor: Torch_AtenGreaterEqualTensorOp,  # type: ignore
    torch.ops.aten.gt.Tensor: Torch_AtenGtTensorOp,  # type: ignore
    torch.ops.aten.less_equal.Tensor: Torch_AtenLessEqualTensorOp,  # type: ignore
    torch.ops.aten.lt.Tensor: Torch_AtenLtTensorOp,  # type: ignore
    torch.ops.aten.less.Tensor: Torch_AtenLessTensorOp,  # type: ignore
    torch.ops.aten.maximum.default: Torch_AtenMaximumOp,  # type: ignore
    torch.ops.aten.minimum.default: Torch_AtenMinimumOp,  # type: ignore
    torch.ops.aten.fmax.default: Torch_AtenFmaxOp,  # type: ignore
    torch.ops.aten.fmin.default: Torch_AtenFminOp,  # type: ignore
    torch.ops.aten.not_equal.Tensor: Torch_AtenNotEqualTensorOp,  # type: ignore
    torch.ops.aten.less_equal_.Tensor: Torch_AtenLessEqual_TensorOp,  # type: ignore
    torch.ops.aten.less_.Tensor: Torch_AtenLess_TensorOp,  # type: ignore
    torch.ops.aten.divide_.Tensor: Torch_AtenDivide_TensorOp,  # type: ignore
    torch.ops.aten.arctan2_.default: Torch_AtenArctan2_Op,  # type: ignore
    torch.ops.aten.greater_.Tensor: Torch_AtenGreater_TensorOp,  # type: ignore
    torch.ops.aten.true_divide_.Tensor: Torch_AtenTrueDivide_TensorOp,  # type: ignore
    torch.ops.aten.floor_divide_.Tensor: Torch_AtenFloorDivide_TensorOp,  # type: ignore
    torch.ops.aten.bitwise_xor_.Tensor: Torch_AtenBitwiseXor_TensorOp,  # type: ignore
    torch.ops.aten.eq_.Tensor: Torch_AtenEq_TensorOp,  # type: ignore
    torch.ops.aten.div_.Tensor: Torch_AtenDiv_TensorOp,  # type: ignore
    torch.ops.aten.greater_equal_.Tensor: Torch_AtenGreaterEqual_TensorOp,  # type: ignore
    torch.ops.aten.nextafter_.default: Torch_AtenNextafter_Op,  # type: ignore
    torch.ops.aten.remainder_.Tensor: Torch_AtenRemainder_TensorOp,  # type: ignore
    torch.ops.aten.ge_.Tensor: Torch_AtenGe_TensorOp,  # type: ignore
    torch.ops.aten.le_.Tensor: Torch_AtenLe_TensorOp,  # type: ignore
    torch.ops.aten.mul_.Tensor: Torch_AtenMul_TensorOp,  # type: ignore
    torch.ops.aten.fmod_.Tensor: Torch_AtenFmod_TensorOp,  # type: ignore
    torch.ops.aten.bitwise_left_shift_.Tensor: Torch_AtenBitwiseLeftShift_TensorOp,  # type: ignore
    torch.ops.aten.gt_.Tensor: Torch_AtenGt_TensorOp,  # type: ignore
    torch.ops.aten.bitwise_or_.Tensor: Torch_AtenBitwiseOr_TensorOp,  # type: ignore
    torch.ops.aten.not_equal_.Tensor: Torch_AtenNotEqual_TensorOp,  # type: ignore
    torch.ops.aten.bitwise_and_.Tensor: Torch_AtenBitwiseAnd_TensorOp,  # type: ignore
    torch.ops.aten.ne_.Tensor: Torch_AtenNe_TensorOp,  # type: ignore
    torch.ops.aten.lt_.Tensor: Torch_AtenLt_TensorOp,  # type: ignore
    torch.ops.aten.multiply_.Tensor: Torch_AtenMultiply_TensorOp,  # type: ignore
    torch.ops.aten.atan2_.default: Torch_AtenAtan2_Op,  # type: ignore
    torch.ops.aten.bitwise_right_shift_.Tensor: Torch_AtenBitwiseRightShift_TensorOp,  # type: ignore
    torch.ops.aten.t.default: Torch_AtenTOp,  # type: ignore
    torch.ops.aten.all.default: Torch_AtenAllOp,  # type: ignore
    torch.ops.aten.abs.default: Torch_AtenAbsOp,  # type: ignore
    torch.ops.aten.absolute.default: Torch_AtenAbsoluteOp,  # type: ignore
    torch.ops.aten.acos.default: Torch_AtenAcosOp,  # type: ignore
    torch.ops.aten.arccos.default: Torch_AtenArccosOp,  # type: ignore
    torch.ops.aten.acosh.default: Torch_AtenAcoshOp,  # type: ignore
    torch.ops.aten.arccosh.default: Torch_AtenArccoshOp,  # type: ignore
    torch.ops.aten.angle.default: Torch_AtenAngleOp,  # type: ignore
    torch.ops.aten.asin.default: Torch_AtenAsinOp,  # type: ignore
    torch.ops.aten.arcsin.default: Torch_AtenArcsinOp,  # type: ignore
    torch.ops.aten.asinh.default: Torch_AtenAsinhOp,  # type: ignore
    torch.ops.aten.arcsinh.default: Torch_AtenArcsinhOp,  # type: ignore
    torch.ops.aten.atan.default: Torch_AtenAtanOp,  # type: ignore
    torch.ops.aten.arctan.default: Torch_AtenArctanOp,  # type: ignore
    torch.ops.aten.atanh.default: Torch_AtenAtanhOp,  # type: ignore
    torch.ops.aten.arctanh.default: Torch_AtenArctanhOp,  # type: ignore
    torch.ops.aten.bitwise_not.default: Torch_AtenBitwiseNotOp,  # type: ignore
    torch.ops.aten.ceil.default: Torch_AtenCeilOp,  # type: ignore
    torch.ops.aten.conj_physical.default: Torch_AtenConjPhysicalOp,  # type: ignore
    torch.ops.aten.cos.default: Torch_AtenCosOp,  # type: ignore
    torch.ops.aten.cosh.default: Torch_AtenCoshOp,  # type: ignore
    torch.ops.aten.deg2rad.default: Torch_AtenDeg2RadOp,  # type: ignore
    torch.ops.aten.digamma.default: Torch_AtenDigammaOp,  # type: ignore
    torch.ops.aten.erf.default: Torch_AtenErfOp,  # type: ignore
    torch.ops.aten.erfc.default: Torch_AtenErfcOp,  # type: ignore
    torch.ops.aten.erfinv.default: Torch_AtenErfinvOp,  # type: ignore
    torch.ops.aten.exp.default: Torch_AtenExpOp,  # type: ignore
    torch.ops.aten.exp2.default: Torch_AtenExp2Op,  # type: ignore
    torch.ops.aten.expm1.default: Torch_AtenExpm1Op,  # type: ignore
    torch.ops.aten.fix.default: Torch_AtenFixOp,  # type: ignore
    torch.ops.aten.floor.default: Torch_AtenFloorOp,  # type: ignore
    torch.ops.aten.frac.default: Torch_AtenFracOp,  # type: ignore
    torch.ops.aten.lgamma.default: Torch_AtenLgammaOp,  # type: ignore
    torch.ops.aten.log.default: Torch_AtenLogOp,  # type: ignore
    torch.ops.aten.log10.default: Torch_AtenLog10Op,  # type: ignore
    torch.ops.aten.log1p.default: Torch_AtenLog1POp,  # type: ignore
    torch.ops.aten.log2.default: Torch_AtenLog2Op,  # type: ignore
    torch.ops.aten.i0.default: Torch_AtenI0Op,  # type: ignore
    torch.ops.aten.isnan.default: Torch_AtenIsnanOp,  # type: ignore
    torch.ops.aten.neg.default: Torch_AtenNegOp,  # type: ignore
    torch.ops.aten.negative.default: Torch_AtenNegativeOp,  # type: ignore
    torch.ops.aten.positive.default: Torch_AtenPositiveOp,  # type: ignore
    torch.ops.aten.pow.Tensor_Tensor: Torch_AtenPowTensorTensorOp,  # type: ignore
    torch.ops.aten.rad2deg.default: Torch_AtenRad2DegOp,  # type: ignore
    torch.ops.aten.reciprocal.default: Torch_AtenReciprocalOp,  # type: ignore
    torch.ops.aten.round.default: Torch_AtenRoundOp,  # type: ignore
    torch.ops.aten.rsqrt.default: Torch_AtenRsqrtOp,  # type: ignore
    torch.ops.aten.sigmoid.default: Torch_AtenSigmoidOp,  # type: ignore
    torch.ops.aten.sign.default: Torch_AtenSignOp,  # type: ignore
    torch.ops.aten.sgn.default: Torch_AtenSgnOp,  # type: ignore
    torch.ops.aten.signbit.default: Torch_AtenSignbitOp,  # type: ignore
    torch.ops.aten.sin.default: Torch_AtenSinOp,  # type: ignore
    torch.ops.aten.sinc.default: Torch_AtenSincOp,  # type: ignore
    torch.ops.aten.sinh.default: Torch_AtenSinhOp,  # type: ignore
    torch.ops.aten.sqrt.default: Torch_AtenSqrtOp,  # type: ignore
    torch.ops.aten.square.default: Torch_AtenSquareOp,  # type: ignore
    torch.ops.aten.tan.default: Torch_AtenTanOp,  # type: ignore
    torch.ops.aten.tanh.default: Torch_AtenTanhOp,  # type: ignore
    torch.ops.aten.trunc.default: Torch_AtenTruncOp,  # type: ignore
    torch.ops.aten.bitwise_not_.default: Torch_AtenBitwiseNot_Op,  # type: ignore
    torch.ops.aten.digamma_.default: Torch_AtenDigamma_Op,  # type: ignore
    torch.ops.aten.cosh_.default: Torch_AtenCosh_Op,  # type: ignore
    torch.ops.aten.floor_.default: Torch_AtenFloor_Op,  # type: ignore
    torch.ops.aten.sign_.default: Torch_AtenSign_Op,  # type: ignore
    torch.ops.aten.fix_.default: Torch_AtenFix_Op,  # type: ignore
    torch.ops.aten.atan_.default: Torch_AtenAtan_Op,  # type: ignore
    torch.ops.aten.arctan_.default: Torch_AtenArctan_Op,  # type: ignore
    torch.ops.aten.frac_.default: Torch_AtenFrac_Op,  # type: ignore
    torch.ops.aten.tan_.default: Torch_AtenTan_Op,  # type: ignore
    torch.ops.aten.trunc_.default: Torch_AtenTrunc_Op,  # type: ignore
    torch.ops.aten.arctanh_.default: Torch_AtenArctanh_Op,  # type: ignore
    torch.ops.aten.log2_.default: Torch_AtenLog2_Op,  # type: ignore
    torch.ops.aten.cos_.default: Torch_AtenCos_Op,  # type: ignore
    torch.ops.aten.log_.default: Torch_AtenLog_Op,  # type: ignore
    torch.ops.aten.reciprocal_.default: Torch_AtenReciprocal_Op,  # type: ignore
    torch.ops.aten.sinh_.default: Torch_AtenSinh_Op,  # type: ignore
    torch.ops.aten.acosh_.default: Torch_AtenAcosh_Op,  # type: ignore
    torch.ops.aten.lgamma_.default: Torch_AtenLgamma_Op,  # type: ignore
    torch.ops.aten.negative_.default: Torch_AtenNegative_Op,  # type: ignore
    torch.ops.aten.arcsinh_.default: Torch_AtenArcsinh_Op,  # type: ignore
    torch.ops.aten.i0_.default: Torch_AtenI0_Op,  # type: ignore
    torch.ops.aten.sin_.default: Torch_AtenSin_Op,  # type: ignore
    torch.ops.aten.atanh_.default: Torch_AtenAtanh_Op,  # type: ignore
    torch.ops.aten.erfc_.default: Torch_AtenErfc_Op,  # type: ignore
    torch.ops.aten.rsqrt_.default: Torch_AtenRsqrt_Op,  # type: ignore
    torch.ops.aten.sqrt_.default: Torch_AtenSqrt_Op,  # type: ignore
    torch.ops.aten.erf_.default: Torch_AtenErf_Op,  # type: ignore
    torch.ops.aten.rad2deg_.default: Torch_AtenRad2Deg_Op,  # type: ignore
    torch.ops.aten.deg2rad_.default: Torch_AtenDeg2Rad_Op,  # type: ignore
    torch.ops.aten.asin_.default: Torch_AtenAsin_Op,  # type: ignore
    torch.ops.aten.acos_.default: Torch_AtenAcos_Op,  # type: ignore
    torch.ops.aten.sgn_.default: Torch_AtenSgn_Op,  # type: ignore
    torch.ops.aten.ceil_.default: Torch_AtenCeil_Op,  # type: ignore
    torch.ops.aten.absolute_.default: Torch_AtenAbsolute_Op,  # type: ignore
    torch.ops.aten.neg_.default: Torch_AtenNeg_Op,  # type: ignore
    torch.ops.aten.asinh_.default: Torch_AtenAsinh_Op,  # type: ignore
    torch.ops.aten.exp2_.default: Torch_AtenExp2_Op,  # type: ignore
    torch.ops.aten.pow_.Tensor: Torch_AtenPow_TensorOp,  # type: ignore
    torch.ops.aten.abs_.default: Torch_AtenAbs_Op,  # type: ignore
    torch.ops.aten.sigmoid_.default: Torch_AtenSigmoid_Op,  # type: ignore
    torch.ops.aten.sinc_.default: Torch_AtenSinc_Op,  # type: ignore
    torch.ops.aten.log1p_.default: Torch_AtenLog1P_Op,  # type: ignore
    torch.ops.aten.round_.default: Torch_AtenRound_Op,  # type: ignore
    torch.ops.aten.tanh_.default: Torch_AtenTanh_Op,  # type: ignore
    torch.ops.aten.arccosh_.default: Torch_AtenArccosh_Op,  # type: ignore
    torch.ops.aten.erfinv_.default: Torch_AtenErfinv_Op,  # type: ignore
    torch.ops.aten.conj_physical_.default: Torch_AtenConjPhysical_Op,  # type: ignore
    torch.ops.aten.log10_.default: Torch_AtenLog10_Op,  # type: ignore
    torch.ops.aten.arccos_.default: Torch_AtenArccos_Op,  # type: ignore
    torch.ops.aten.square_.default: Torch_AtenSquare_Op,  # type: ignore
    torch.ops.aten.expm1_.default: Torch_AtenExpm1_Op,  # type: ignore
    torch.ops.aten.exp_.default: Torch_AtenExp_Op,  # type: ignore
    torch.ops.aten.arcsin_.default: Torch_AtenArcsin_Op,  # type: ignore
    torch.ops.aten.fill.Tensor: Torch_AtenFillTensorOp,  # type: ignore
    torch.ops.aten.imag.default: Torch_AtenImagOp,  # type: ignore
    torch.ops.aten.isfinite.default: Torch_AtenIsfiniteOp,  # type: ignore
    torch.ops.aten.real.default: Torch_AtenRealOp,  # type: ignore
    torch.ops.aten.gcd.default: Torch_AtenGcdOp,  # type: ignore
    torch.ops.aten.hypot.default: Torch_AtenHypotOp,  # type: ignore
    torch.ops.aten.igamma.default: Torch_AtenIgammaOp,  # type: ignore
    torch.ops.aten.igammac.default: Torch_AtenIgammacOp,  # type: ignore
    torch.ops.aten.conj.default: Torch_AtenConjOp,  # type: ignore
    torch.ops.aten.squeeze.default: Torch_AtenSqueezeOp,  # type: ignore
    torch.ops.aten.where.self: Torch_AtenWhereSelfOp,  # type: ignore
    torch.ops.aten.frexp.Tensor: Torch_AtenFrexpTensorOp,  # type: ignore
    torch.ops.aten.mm.default: Torch_AtenMmOp,  # type: ignore
    torch.ops.aten.tanh_backward.default: Torch_AtenTanhBackwardOp,  # type: ignore
    torch.ops.aten.tanh_backward.grad_input: Torch_AtenTanhBackwardGradInputOp,  # type: ignore
    torch.ops.aten.sigmoid_backward.default: Torch_AtenSigmoidBackwardOp,  # type: ignore
    torch.ops.aten.sigmoid_backward.grad_input: Torch_AtenSigmoidBackwardGradInputOp,  # type: ignore
    torch.ops.aten.hardsigmoid.default: Torch_AtenHardsigmoidOp,  # type: ignore
    torch.ops.aten.hardsigmoid_backward.default: Torch_AtenHardsigmoidBackwardOp,  # type: ignore
    torch.ops.aten.hardsigmoid_backward.grad_input: Torch_AtenHardsigmoidBackwardGradInputOp,  # type: ignore
    torch.ops.aten.hardswish.default: Torch_AtenHardswishOp,  # type: ignore
    torch.ops.aten.hardswish_backward.default: Torch_AtenHardswishBackwardOp,  # type: ignore
    torch.ops.aten.mish_backward.default: Torch_AtenMishBackwardOp,  # type: ignore
    torch.ops.aten.silu.default: Torch_AtenSiluOp,  # type: ignore
    torch.ops.aten.silu_backward.default: Torch_AtenSiluBackwardOp,  # type: ignore
    torch.ops.aten.silu_backward.grad_input: Torch_AtenSiluBackwardGradInputOp,  # type: ignore
    torch.ops.aten._prelu_kernel.default: Torch_Aten_PreluKernelOp,  # type: ignore
    torch.ops.aten._prelu_kernel_backward.default: Torch_Aten_PreluKernelBackwardOp,  # type: ignore
    torch.ops.aten.log_sigmoid_backward.default: Torch_AtenLogSigmoidBackwardOp,  # type: ignore
    torch.ops.aten.log_sigmoid_backward.grad_input: Torch_AtenLogSigmoidBackwardGradInputOp,  # type: ignore
    torch.ops.aten._euclidean_dist.default: Torch_Aten_EuclideanDistOp,  # type: ignore
    torch.ops.aten.lift.default: Torch_AtenLiftOp,  # type: ignore
    torch.ops.aten.log_sigmoid_forward.default: Torch_AtenLogSigmoidForwardOp,  # type: ignore
    torch.ops.aten.mv.default: Torch_AtenMvOp,  # type: ignore
    torch.ops.aten.matmul.default: Torch_AtenMatmulOp,  # type: ignore
    torch.ops.aten.take.default: Torch_AtenTakeOp,  # type: ignore
    torch.ops.aten.fill_.Tensor: Torch_AtenFill_TensorOp,  # type: ignore
    torch.ops.aten.hardswish_.default: Torch_AtenHardswish_Op,  # type: ignore
    torch.ops.aten.hardsigmoid_.default: Torch_AtenHardsigmoid_Op,  # type: ignore
    torch.ops.aten.__iand__.Tensor: Torch_Aten_Iand_TensorOp,  # type: ignore
    torch.ops.aten.__and__.Tensor: Torch_Aten_And_TensorOp,  # type: ignore
    torch.ops.aten.__ilshift__.Tensor: Torch_Aten_Ilshift_TensorOp,  # type: ignore
    torch.ops.aten.__lshift__.Tensor: Torch_Aten_Lshift_TensorOp,  # type: ignore
    torch.ops.aten.__ior__.Tensor: Torch_Aten_Ior_TensorOp,  # type: ignore
    torch.ops.aten.__or__.Tensor: Torch_Aten_Or_TensorOp,  # type: ignore
    torch.ops.aten.__irshift__.Tensor: Torch_Aten_Irshift_TensorOp,  # type: ignore
    torch.ops.aten.__rshift__.Tensor: Torch_Aten_Rshift_TensorOp,  # type: ignore
    torch.ops.aten.__ixor__.Tensor: Torch_Aten_Ixor_TensorOp,  # type: ignore
    torch.ops.aten.__xor__.Tensor: Torch_Aten_Xor_TensorOp,  # type: ignore
    torch.ops.aten.relu_.default: Torch_AtenRelu_Op,  # type: ignore
    torch.ops.aten.relu.default: Torch_AtenReluOp,  # type: ignore
    torch.ops.aten.silu_.default: Torch_AtenSilu_Op,  # type: ignore
    torch.ops.aten.zero.default: Torch_AtenZeroOp,  # type: ignore
    torch.ops.aten.isinf.default: Torch_AtenIsinfOp,  # type: ignore
    torch.ops.aten.isposinf.default: Torch_AtenIsposinfOp,  # type: ignore
    torch.ops.aten.isneginf.default: Torch_AtenIsneginfOp,  # type: ignore
    torch.ops.aten.copysign.Tensor: Torch_AtenCopysignTensorOp,  # type: ignore
    torch.ops.aten.heaviside.default: Torch_AtenHeavisideOp,  # type: ignore
    torch.ops.aten.lcm.default: Torch_AtenLcmOp,  # type: ignore
    torch.ops.aten.logical_and.default: Torch_AtenLogicalAndOp,  # type: ignore
    torch.ops.aten.logical_not.default: Torch_AtenLogicalNotOp,  # type: ignore
    torch.ops.aten.logical_or.default: Torch_AtenLogicalOrOp,  # type: ignore
    torch.ops.aten.logical_xor.default: Torch_AtenLogicalXorOp,  # type: ignore
    torch.ops.aten.xlogy.Tensor: Torch_AtenXlogyTensorOp,  # type: ignore
    torch.ops.aten.xlogy.OutTensor: Torch_AtenXlogyOuttensorOp,  # type: ignore
    torch.ops.aten.clamp_min.Tensor: Torch_AtenClampMinTensorOp,  # type: ignore
    torch.ops.aten.clamp_max.Tensor: Torch_AtenClampMaxTensorOp,  # type: ignore
    torch.ops.aten.any.default: Torch_AtenAnyOp,  # type: ignore
    torch.ops.aten.alias.default: Torch_AtenAliasOp,  # type: ignore
    torch.ops.aten.lerp.Tensor: Torch_AtenLerpTensorOp,  # type: ignore
    torch.ops.aten.masked_fill.Tensor: Torch_AtenMaskedFillTensorOp,  # type: ignore
    torch.ops.aten.masked_fill_.Tensor: Torch_AtenMaskedFill_TensorOp,  # type: ignore
    torch.ops.aten.trace.default: Torch_AtenTraceOp,  # type: ignore
    torch.ops.aten.dot.default: Torch_AtenDotOp,  # type: ignore
    torch.ops.aten.vdot.default: Torch_AtenVdotOp,  # type: ignore
    torch.ops.aten.clamp_min_.Tensor: Torch_AtenClampMin_TensorOp,  # type: ignore
    torch.ops.aten.clamp_max_.Tensor: Torch_AtenClampMax_TensorOp,  # type: ignore
    torch.ops.aten.copysign_.Tensor: Torch_AtenCopysign_TensorOp,  # type: ignore
    torch.ops.aten.float_power_.Tensor: Torch_AtenFloatPower_TensorOp,  # type: ignore
    torch.ops.aten.gcd_.default: Torch_AtenGcd_Op,  # type: ignore
    torch.ops.aten.heaviside_.default: Torch_AtenHeaviside_Op,  # type: ignore
    torch.ops.aten.hypot_.default: Torch_AtenHypot_Op,  # type: ignore
    torch.ops.aten.igamma_.default: Torch_AtenIgamma_Op,  # type: ignore
    torch.ops.aten.igammac_.default: Torch_AtenIgammac_Op,  # type: ignore
    torch.ops.aten.lcm_.default: Torch_AtenLcm_Op,  # type: ignore
    torch.ops.aten.lerp_.Tensor: Torch_AtenLerp_TensorOp,  # type: ignore
    torch.ops.aten.logical_and_.default: Torch_AtenLogicalAnd_Op,  # type: ignore
    torch.ops.aten.logical_not_.default: Torch_AtenLogicalNot_Op,  # type: ignore
    torch.ops.aten.logical_or_.default: Torch_AtenLogicalOr_Op,  # type: ignore
    torch.ops.aten.logical_xor_.default: Torch_AtenLogicalXor_Op,  # type: ignore
    torch.ops.aten.xlogy_.Tensor: Torch_AtenXlogy_TensorOp,  # type: ignore
    torch.ops.aten.zero_.default: Torch_AtenZero_Op,  # type: ignore
    torch.ops.aten.alias_copy.default: Torch_AtenAliasCopyOp,  # type: ignore
    torch.ops.aten.squeeze_copy.default: Torch_AtenSqueezeCopyOp,  # type: ignore
    torch.ops.aten.t_copy.default: Torch_AtenTCopyOp,  # type: ignore
    torch.ops.aten.complex.default: Torch_AtenComplexOp,  # type: ignore
    torch.ops.aten.polar.default: Torch_AtenPolarOp,  # type: ignore
    torch.ops.aten.mish.default: Torch_AtenMishOp,  # type: ignore
    torch.ops.aten.selu.default: Torch_AtenSeluOp,  # type: ignore
    torch.ops.aten.prelu.default: Torch_AtenPreluOp,  # type: ignore
    torch.ops.aten.relu6.default: Torch_AtenRelu6Op,  # type: ignore
    torch.ops.aten.mish_.default: Torch_AtenMish_Op,  # type: ignore
    torch.ops.aten.selu_.default: Torch_AtenSelu_Op,  # type: ignore
    torch.ops.aten.special_bessel_j0.default: Torch_AtenSpecialBesselJ0Op,  # type: ignore
    torch.ops.aten.special_bessel_j1.default: Torch_AtenSpecialBesselJ1Op,  # type: ignore
    torch.ops.aten.special_entr.default: Torch_AtenSpecialEntrOp,  # type: ignore
    torch.ops.aten.special_erfcx.default: Torch_AtenSpecialErfcxOp,  # type: ignore
    torch.ops.aten.special_i0e.default: Torch_AtenSpecialI0EOp,  # type: ignore
    torch.ops.aten.special_i1.default: Torch_AtenSpecialI1Op,  # type: ignore
    torch.ops.aten.special_i1e.default: Torch_AtenSpecialI1EOp,  # type: ignore
    torch.ops.aten.special_log_ndtr.default: Torch_AtenSpecialLogNdtrOp,  # type: ignore
    torch.ops.aten.special_xlog1py.default: Torch_AtenSpecialXlog1PyOp,  # type: ignore
    torch.ops.aten.special_ndtr.default: Torch_AtenSpecialNdtrOp,  # type: ignore
    torch.ops.aten.special_ndtri.default: Torch_AtenSpecialNdtriOp,  # type: ignore
    torch.ops.aten.special_spherical_bessel_j0.default: Torch_AtenSpecialSphericalBesselJ0Op,  # type: ignore
    torch.ops.aten.special_zeta.default: Torch_AtenSpecialZetaOp,  # type: ignore
    torch.ops.aten.linalg_matrix_exp.default: Torch_AtenLinalgMatrixExpOp,  # type: ignore
    torch.ops.aten.max.other: Torch_AtenMaxOtherOp,  # type: ignore
    torch.ops.aten.max.default: Torch_AtenMaxOp,  # type: ignore
    torch.ops.aten.min.other: Torch_AtenMinOtherOp,  # type: ignore
    torch.ops.aten.min.default: Torch_AtenMinOp,  # type: ignore
    torch.ops.aten._linalg_eigvals.default: Torch_Aten_LinalgEigvalsOp,  # type: ignore
    torch.ops.aten.linalg_eigvals.default: Torch_AtenLinalgEigvalsOp,  # type: ignore
    torch.ops.aten.linalg_eig.default: Torch_AtenLinalgEigOp,  # type: ignore
    torch.ops.aten.linalg_householder_product.default: Torch_AtenLinalgHouseholderProductOp,  # type: ignore
    torch.ops.aten._linalg_slogdet.default: Torch_Aten_LinalgSlogdetOp,  # type: ignore
    torch.ops.aten._linalg_det.default: Torch_Aten_LinalgDetOp,  # type: ignore
    torch.ops.aten._adaptive_avg_pool2d_backward.default: Torch_Aten_AdaptiveAvgPool2DBackwardOp,  # type: ignore
    torch.ops.aten._adaptive_avg_pool3d_backward.default: Torch_Aten_AdaptiveAvgPool3DBackwardOp,  # type: ignore
    torch.ops.aten.adaptive_max_pool2d_backward.default: Torch_AtenAdaptiveMaxPool2DBackwardOp,  # type: ignore
    torch.ops.aten.adaptive_max_pool2d_backward.grad_input: Torch_AtenAdaptiveMaxPool2DBackwardGradInputOp,  # type: ignore
    torch.ops.aten.adaptive_max_pool3d_backward.default: Torch_AtenAdaptiveMaxPool3DBackwardOp,  # type: ignore
    torch.ops.aten.adaptive_max_pool3d_backward.grad_input: Torch_AtenAdaptiveMaxPool3DBackwardGradInputOp,  # type: ignore
    torch.ops.aten._int_mm.default: Torch_Aten_IntMmOp,  # type: ignore
    torch.ops.aten._weight_int8pack_mm.default: Torch_Aten_WeightInt8PackMmOp,  # type: ignore
    torch.ops.aten.median.default: Torch_AtenMedianOp,  # type: ignore
    torch.ops.aten.nanmedian.default: Torch_AtenNanmedianOp,  # type: ignore
    torch.ops.aten.masked_scatter_.default: Torch_AtenMaskedScatter_Op,  # type: ignore
    torch.ops.aten.masked_scatter.default: Torch_AtenMaskedScatterOp,  # type: ignore
    torch.ops.aten.bmm.default: Torch_AtenBmmOp,  # type: ignore
    torch.ops.aten.t_.default: Torch_AtenT_Op,  # type: ignore
    torch.ops.aten.special_airy_ai.default: Torch_AtenSpecialAiryAiOp,  # type: ignore
    torch.ops.aten.special_bessel_y0.default: Torch_AtenSpecialBesselY0Op,  # type: ignore
    torch.ops.aten.special_bessel_y1.default: Torch_AtenSpecialBesselY1Op,  # type: ignore
    torch.ops.aten.special_modified_bessel_i0.default: Torch_AtenSpecialModifiedBesselI0Op,  # type: ignore
    torch.ops.aten.special_modified_bessel_i1.default: Torch_AtenSpecialModifiedBesselI1Op,  # type: ignore
    torch.ops.aten.special_modified_bessel_k0.default: Torch_AtenSpecialModifiedBesselK0Op,  # type: ignore
    torch.ops.aten.special_modified_bessel_k1.default: Torch_AtenSpecialModifiedBesselK1Op,  # type: ignore
    torch.ops.aten.special_scaled_modified_bessel_k0.default: Torch_AtenSpecialScaledModifiedBesselK0Op,  # type: ignore
    torch.ops.aten.special_scaled_modified_bessel_k1.default: Torch_AtenSpecialScaledModifiedBesselK1Op,  # type: ignore
    torch.ops.aten.special_chebyshev_polynomial_t.default: Torch_AtenSpecialChebyshevPolynomialTOp,  # type: ignore
    torch.ops.aten.special_chebyshev_polynomial_u.default: Torch_AtenSpecialChebyshevPolynomialUOp,  # type: ignore
    torch.ops.aten.special_chebyshev_polynomial_v.default: Torch_AtenSpecialChebyshevPolynomialVOp,  # type: ignore
    torch.ops.aten.special_chebyshev_polynomial_w.default: Torch_AtenSpecialChebyshevPolynomialWOp,  # type: ignore
    torch.ops.aten.special_shifted_chebyshev_polynomial_t.default: Torch_AtenSpecialShiftedChebyshevPolynomialTOp,  # type: ignore
    torch.ops.aten.special_shifted_chebyshev_polynomial_u.default: Torch_AtenSpecialShiftedChebyshevPolynomialUOp,  # type: ignore
    torch.ops.aten.special_shifted_chebyshev_polynomial_v.default: Torch_AtenSpecialShiftedChebyshevPolynomialVOp,  # type: ignore
    torch.ops.aten.special_shifted_chebyshev_polynomial_w.default: Torch_AtenSpecialShiftedChebyshevPolynomialWOp,  # type: ignore
    torch.ops.aten.special_hermite_polynomial_h.default: Torch_AtenSpecialHermitePolynomialHOp,  # type: ignore
    torch.ops.aten.special_hermite_polynomial_he.default: Torch_AtenSpecialHermitePolynomialHeOp,  # type: ignore
    torch.ops.aten.special_laguerre_polynomial_l.default: Torch_AtenSpecialLaguerrePolynomialLOp,  # type: ignore
    torch.ops.aten.special_legendre_polynomial_p.default: Torch_AtenSpecialLegendrePolynomialPOp,  # type: ignore
    torch.ops.profiler._record_function_exit.default: Torch_Profiler_RecordFunctionExitOp,  # type: ignore
    torch.ops.inductor.accumulate_grad_.default: Torch_InductorAccumulateGrad_Op,  # type: ignore
    torch.ops.prims.abs.default: Torch_PrimsAbsOp,  # type: ignore
    torch.ops.prims.acos.default: Torch_PrimsAcosOp,  # type: ignore
    torch.ops.prims.acosh.default: Torch_PrimsAcoshOp,  # type: ignore
    torch.ops.prims.asin.default: Torch_PrimsAsinOp,  # type: ignore
    torch.ops.prims.asinh.default: Torch_PrimsAsinhOp,  # type: ignore
    torch.ops.prims.atan.default: Torch_PrimsAtanOp,  # type: ignore
    torch.ops.prims.atanh.default: Torch_PrimsAtanhOp,  # type: ignore
    torch.ops.prims.cos.default: Torch_PrimsCosOp,  # type: ignore
    torch.ops.prims.cosh.default: Torch_PrimsCoshOp,  # type: ignore
    torch.ops.prims.bessel_j0.default: Torch_PrimsBesselJ0Op,  # type: ignore
    torch.ops.prims.bessel_j1.default: Torch_PrimsBesselJ1Op,  # type: ignore
    torch.ops.prims.bessel_i0.default: Torch_PrimsBesselI0Op,  # type: ignore
    torch.ops.prims.bessel_i0e.default: Torch_PrimsBesselI0EOp,  # type: ignore
    torch.ops.prims.bessel_i1.default: Torch_PrimsBesselI1Op,  # type: ignore
    torch.ops.prims.bessel_i1e.default: Torch_PrimsBesselI1EOp,  # type: ignore
    torch.ops.prims.bitwise_not.default: Torch_PrimsBitwiseNotOp,  # type: ignore
    torch.ops.prims.cbrt.default: Torch_PrimsCbrtOp,  # type: ignore
    torch.ops.prims.ceil.default: Torch_PrimsCeilOp,  # type: ignore
    torch.ops.prims.conj_physical.default: Torch_PrimsConjPhysicalOp,  # type: ignore
    torch.ops.prims.digamma.default: Torch_PrimsDigammaOp,  # type: ignore
    torch.ops.prims.erf.default: Torch_PrimsErfOp,  # type: ignore
    torch.ops.prims.erf_inv.default: Torch_PrimsErfInvOp,  # type: ignore
    torch.ops.prims.erfc.default: Torch_PrimsErfcOp,  # type: ignore
    torch.ops.prims.erfcx.default: Torch_PrimsErfcxOp,  # type: ignore
    torch.ops.prims.exp.default: Torch_PrimsExpOp,  # type: ignore
    torch.ops.prims.expm1.default: Torch_PrimsExpm1Op,  # type: ignore
    torch.ops.prims.exp2.default: Torch_PrimsExp2Op,  # type: ignore
    torch.ops.prims.floor.default: Torch_PrimsFloorOp,  # type: ignore
    torch.ops.prims.imag.default: Torch_PrimsImagOp,  # type: ignore
    torch.ops.prims.isfinite.default: Torch_PrimsIsfiniteOp,  # type: ignore
    torch.ops.prims.lgamma.default: Torch_PrimsLgammaOp,  # type: ignore
    torch.ops.prims.log.default: Torch_PrimsLogOp,  # type: ignore
    torch.ops.prims.log1p.default: Torch_PrimsLog1POp,  # type: ignore
    torch.ops.prims.log2.default: Torch_PrimsLog2Op,  # type: ignore
    torch.ops.prims.log10.default: Torch_PrimsLog10Op,  # type: ignore
    torch.ops.prims.real.default: Torch_PrimsRealOp,  # type: ignore
    torch.ops.prims.reciprocal.default: Torch_PrimsReciprocalOp,  # type: ignore
    torch.ops.prims.ndtri.default: Torch_PrimsNdtriOp,  # type: ignore
    torch.ops.prims.neg.default: Torch_PrimsNegOp,  # type: ignore
    torch.ops.prims.round.default: Torch_PrimsRoundOp,  # type: ignore
    torch.ops.prims.rsqrt.default: Torch_PrimsRsqrtOp,  # type: ignore
    torch.ops.prims.sign.default: Torch_PrimsSignOp,  # type: ignore
    torch.ops.prims.signbit.default: Torch_PrimsSignbitOp,  # type: ignore
    torch.ops.prims.sin.default: Torch_PrimsSinOp,  # type: ignore
    torch.ops.prims.sinh.default: Torch_PrimsSinhOp,  # type: ignore
    torch.ops.prims.spherical_bessel_j0.default: Torch_PrimsSphericalBesselJ0Op,  # type: ignore
    torch.ops.prims.sqrt.default: Torch_PrimsSqrtOp,  # type: ignore
    torch.ops.prims.tan.default: Torch_PrimsTanOp,  # type: ignore
    torch.ops.prims.tanh.default: Torch_PrimsTanhOp,  # type: ignore
    torch.ops.prims.trunc.default: Torch_PrimsTruncOp,  # type: ignore
    torch.ops.prims.add.default: Torch_PrimsAddOp,  # type: ignore
    torch.ops.prims.atan2.default: Torch_PrimsAtan2Op,  # type: ignore
    torch.ops.prims.bitwise_and.default: Torch_PrimsBitwiseAndOp,  # type: ignore
    torch.ops.prims.bitwise_or.default: Torch_PrimsBitwiseOrOp,  # type: ignore
    torch.ops.prims.bitwise_xor.default: Torch_PrimsBitwiseXorOp,  # type: ignore
    torch.ops.prims.div.default: Torch_PrimsDivOp,  # type: ignore
    torch.ops.prims.eq.default: Torch_PrimsEqOp,  # type: ignore
    torch.ops.prims.fmax.default: Torch_PrimsFmaxOp,  # type: ignore
    torch.ops.prims.fmin.default: Torch_PrimsFminOp,  # type: ignore
    torch.ops.prims.fmod.default: Torch_PrimsFmodOp,  # type: ignore
    torch.ops.prims.gcd.default: Torch_PrimsGcdOp,  # type: ignore
    torch.ops.prims.ge.default: Torch_PrimsGeOp,  # type: ignore
    torch.ops.prims.gt.default: Torch_PrimsGtOp,  # type: ignore
    torch.ops.prims.hypot.default: Torch_PrimsHypotOp,  # type: ignore
    torch.ops.prims.igamma.default: Torch_PrimsIgammaOp,  # type: ignore
    torch.ops.prims.igammac.default: Torch_PrimsIgammacOp,  # type: ignore
    torch.ops.prims.le.default: Torch_PrimsLeOp,  # type: ignore
    torch.ops.prims.lt.default: Torch_PrimsLtOp,  # type: ignore
    torch.ops.prims.maximum.default: Torch_PrimsMaximumOp,  # type: ignore
    torch.ops.prims.minimum.default: Torch_PrimsMinimumOp,  # type: ignore
    torch.ops.prims.mul.default: Torch_PrimsMulOp,  # type: ignore
    torch.ops.prims.ne.default: Torch_PrimsNeOp,  # type: ignore
    torch.ops.prims.nextafter.default: Torch_PrimsNextafterOp,  # type: ignore
    torch.ops.prims.pow.default: Torch_PrimsPowOp,  # type: ignore
    torch.ops.prims.remainder.default: Torch_PrimsRemainderOp,  # type: ignore
    torch.ops.prims.shift_left.default: Torch_PrimsShiftLeftOp,  # type: ignore
    torch.ops.prims.shift_right_arithmetic.default: Torch_PrimsShiftRightArithmeticOp,  # type: ignore
    torch.ops.prims.sub.default: Torch_PrimsSubOp,  # type: ignore
    torch.ops.prims.zeta.default: Torch_PrimsZetaOp,  # type: ignore
    torch.ops.prims.conj.default: Torch_PrimsConjOp,  # type: ignore
    torch.ops.prims.view_of.default: Torch_PrimsViewOfOp,  # type: ignore
    torch.ops.prims.where.default: Torch_PrimsWhereOp,  # type: ignore
    torch.ops.prims.copy_to.default: Torch_PrimsCopyToOp,  # type: ignore
    torch.ops.prims.frexp.default: Torch_PrimsFrexpOp,  # type: ignore
    torch.ops.prims._make_token.default: Torch_Prims_MakeTokenOp,  # type: ignore
}

REVERSE_XDSL_TORCH_OPS = {
    xdsl_op: torch_op for torch_op, xdsl_op in XDSL_TORCH_OPS.items()
}
